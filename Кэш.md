Проблема во времени доступа к оперативной памяти, т. к. скорость работы процессора намного больше скорости работы ОЗУ, из-за чего процессор может простаивать, ожидая получения данных. Для решения этой проблемы создали кэш. Кэш состоит из контроллера и памяти. Память кэша, как и оперативная, использует двоичную адресацию, при которой размер памяти должен быть кратен степени двойки.

Запись данных в оперативную память происходит пакетами, размер которых может составлять несколько машинных слов. Такой объем информации процессор не может поместить в регистр, поэтому данные сохраняются в кэше.

При обращении к памяти контроллер перехватывает запрос, проверяя, есть ли копия данных в кэше, если нет, то запрос передается оперативной памяти. Измененные данные записываются обратно в кэш, позже они будут выгружены в оперативную память. Обычно это происходит при замене данных в кэше на новые. Такой режим работы называется "Write back". Есть режим "Write Through", когда данные записываются как в кэш, так и в оперативную память, но он работает медленнее. 

## Выгрузка данных
Для того, чтобы выгрузить данные из кэша обратно в оперативную память, надо знать, где они должны быть. Хранение в формате адрес байта и сам байт займет много места, например на 32-битной системе размер адреса 4 байта, итого потребуется 5 байт. Поэтому данные в кэше хранятся не в виде отдельных байтов, а в виде блоков, в которых данные идут подряд, это называется кэш-строкой. Кэш использует строки, так как предполагает, что данные, расположенные рядом с текущими (изменяющимися), скорее всего тоже будут изменены, поэтому они заранее загружаются. На процессорах x86 размер кэш-строки состовляет 64 байта. Тогда можно сохранять только адрес певого байта. 

## Размер кэша
Полный размер кэша складывается из полезных данных и служебных. Например, если размер кэша 128 байт, 4 строки по 32 байта, то полный размер будет 128 + 4 * 4 = 144 байта (4 байта для адреса каждой строки). 

## Кэш прямого отображения
Оперативная память делится на сегменты, размер каждого сегмента равен размеру кэша, каждый сегмент делится на блоки, размер каждого блока равен размеру кэш-строки.

Для нахождения данных в кэше делим адрес данных на размер кэш-строки и находим остаток от деления этого числа на количество кэш-строк, получая индекс нужной кэш-строки. Например, у нас кэш размером 256 байт, состоящий из 4-х строк размерами по 64 байта, и мы хотим определить, в какой строке будут данные по адресу 678. Для этого считаем: 678 / 64 %  4 = 2.

Кэш-строка состоит из:
- Доп информация. Указывает, используется ли строка в данный момент, нужно для алгоритма замещения
- Тэг. Адрес первого байта в строке.
- Блок данных.

32-битный адрес состоит из: 
- Тэг. Старшая часть адреса байта, т. е. номер сегмента
- Индекс строки
- Смещение в строке до нужного байта

Размер смещения зависит от длины кэш-строки, если размер строки 64 байта, то нужно 6 бит для обращения к любому из них, если 32 байта, то 5 бит и т. д. Так как 32-битный ЦП считывает данные словами размером 4 байта, то 6-битное смещение состоит из 2 частей: 
- 4 бита для поиска слова, в 64-байтовой строке их 16
- 2 бита для поиска байта внутри слова, в 32-битном слове их 4

Размер индекса строки зависит от количества строк кэша, например для того, чтобы обратиться к любой из 4 строк нужно 2 бита. 

Итого:
- Первые 2 бита (самые правые) могут принимать значения от 00 до 11, это индекс байта в слове. 
- Следующие 4 бита принимают значения от 0000 до 1111, это индекс слова в строке.
- Следующие 2 бита дают индекс строки. Когда загрузим следующие за текущей строкой 64 байта, то значение в этих двух битах увеличится на один, таким образом индекс строки увеличится.
- Остается 24 бита, которые указывают на номер сегмента.

Для проверки того, есть ли нужные данные в кэше, из адреса извлекается индекс строки, затем сравниваются тэг (необходимое кол-во старших бит) кэш-строки по этому индексу со тэгом адреса данных (необходимое кол-во старших бит). 

Так как в одном сегменте никакие два блока (равные по размеру кэш-строке) не могут отображаться на одну и ту же кэш-строку, то зная индекс строки и старшие части адреса первого байта в строке и адреса запрашиваемых данных, можем однозначно сказать, есть ли эти данные в кэше или нет. 

Фактически мы сравниваем номера сегментов, в которых находятся адрес первого байта в строке и адрес запрашиваемых данных. С изначальным адресом байта ничего не происходит, посредством битовых операций из него получают все необходимые данные.

Главный недостаток такого кэша в том, то разные строки из оперативной памяти претендуют занять одну и ту же сроку в кэш памяти, из-за этого высока вероятность коллизий. 

## Наборно-ассоциативный кэш
Создан для уменьшения вероятности коллизий. Кэш делится на сегменты, называемые каналами, каждый из которых является кэшом прямого отображения, при этом любая строка оперативной памяти может быть размещена в любом канале, но внутри определенного канала ей будет соответствовать строго определенная кэш-строка. Количество каналов должно быть кратно степени двойки. 

Например 4-х канальный кэш в каждом из которых 4 строки. Так же, как и в кэше прямого отображения находим индекс строки в которой должны быть данные, и одновременно сравниваем строки по этому индексу (сравнение такое же, как и в кэше прямого отображения) во всех каналах. 

## Полностью ассоциативный кэш
Еще больше уменьшает вероятность коллизий. Любая строка из оперативной памяти может попасть в любую строку кэша, но у этого кэша низкая производительность, так как приходится перебирать все строки кэша. 

## Замещение
Замещения только по требованию (в случае, когда данные будут обновлены только при запросе процессора) приводит к большому количеству промахов. Для оптимизации кэш-контроллер пытается предсказать, какие данные понадобятся процессору.

Алгоритмы выгрузки данных:
- Алгоритм LRU (least recently used) замещает те данные, к которым дольше всего не было обращений. 
- Алгоритм MFU (most frequently used) наоборот, замещает последние используемые данные. 
- Алгоритм LFU (least frequently used) замещает данные, которые использовались реже всех.

Эти алгоритмы требуют добавления в служебные данные счетчика возраста, которые обновляются при каждом обращении к любой строке. 

Алгоритмы для выбора строк которые, вероятно, понадобятся процессору, могут быть как простым предположением о том, что могут потребоваться соседние с текущей строкой данные, так и сложными стратегиями, основанными на анализе предыдущих обращений и анализа промахов. 

## Многоуровневый кэш
При увеличении размера кэша увеличивается время на поиск и получение данных, и его скорость падает, из-за этого нужен баланс между размером и скоростью. Использование нескольких небольших кэшей будет лучшим вариантом, чем использование большого, но медленного. 

Для этого используется иерархическая структура кэша, например L1, L2, L3. 
L1 делится на 8-канальный кэш данных и 4-х канальный кэш инструкций по 32 Кб на каждый кэш. Он принадлежит конкретному ядру.  L2 8-канальный размером 512 Кб, при этом он медленее L1, тоже принадлежит конкретному ядру (в данном случае, но так же может быть общим). L3 16-канальный размером 2 Мб, медленее L2, общий между всеми ядрами. 

## Взаимодействие уровней
Рассмотрим на примере кэшей L1 и L2. Может быть инклюзивная архитектура, при которой L2 дублирует L1, и эксклюзивная, при которой содержимое не дублируется. 

При инклюзивной архитектуре строка из оперативной памяти загружается в L2. Если он заполнен, заменяется наименее ценная строка, например та, которая не была модифицированна (чтобы ее не пришлось выгружать), далее L2 передает данные L1. Если он тоже заполнен, то опять ищутся строки, которые можно перезаписать. В итоге данные будут как в L1, так и в L2.

При эксклюзивной архитектуре начало такое же, но при нехватке места в L1 вместо перезаписи в нем старой строки L1 обменивается ей с L2, т. е. L2 передает в L1 новую строку, а L1 передает L2 старую. Таким образом данные могут быть только в одном из

Рассмотрим 3-х уровневый кэш где L3 является включающим по отношению к L1 и L2, при этом L1 и L2 ни включающие, ни исключающие по отношению друг к другу, т. е. L2 может содержать данные из L1, а может и нет. Когда процессору потребуются данные, они будут искаться в L1, если не найдет, то в L2, если промах и L3 включающий, то в нем можно не искать, так как этих данных в нем точно нет, если бы L3 был исключающим, то искать пришлось бы. 

В многоядерном процессоре эта разница становится существенной. Если получили промах в одном из ядер и L3 включающий, то искать эти данные по другим ядрам не придется, так как этих данных в них гарантированно нет. При этом если кэш исключающий, то пришлось бы производить поиск в других ядрах. Плюс включающей архитектуры в более быстром поиске, но данных при этом хранить можно меньше.


## Когерентность
Далее под процессорами будут подразумеваться как несколько CPU, так и несколько ядер одного процессора. 

При многопроцессорной архитектуре одни и те же данные могут использоваться одновременно несколькими кэшами, поэтому может возникнуть ситуация, когда копия данных была изменена в кэше, но не была выгружена в оперативную память, и к этим данным обращается другой процессор. Другой момент, если в каждом из кэшей будут модифицироваться одни и те же данные, это приведет к сложности слияния изменений при выгрузке в оперативную память, поэтому нужно иметь возможность различать, совпадает ли копия данных в кэше со своей копией в оперативной памяти. Согласованность содержимого кэш-памяти и оперативной памяти называется когерентностью кэша. 

Для реализации были введены специальные состояния, при которых только в одном кэше может изменяться одна конкретная кэш строка, при этом реализации могут сильно отличаться. 

### Протокол MSI
Для примера три процессора и три абстрактных кэша. 
Первый процессор отправляет запрос на получение строки из оперативной памяти. Ей присваивается состояние S (shared), означает что в данной строке свежие данные, совпадающие с данными из оперативной памяти, а так же то, что эта строка может присутствовать в других кэшах. Это дает возможность читать одни и те же строки сразу всем процессорам. 

Когда первому процессору требуется внести изменения в свою строку, для этого нужно сообщить остальным процессорам, что копии строки перестают быть актуальными, поэтому копии переходят в состояние I (invalid), после этого первый процессор вносит изменения в свою строку, меняя состояние на M (modified), что значит данные новее чем те, которые в оперативной памяти, и если понадобится, то первый процессор сможет еще раз внести изменения без каких-либо дополнительных операций.

При этом если третий процессор отправит запрос на получение той же строки, пока она в модифицированном состоянии в первом процессоре, запрос прервется, так как брать данные из оперативной памяти нельзя (они устаревшие). Третий процессор сможет получить доступ к первой строке только после того, как первый выгрузит ее в оперативную память, после чего она поменяет статус на S. 

### Протокол MESI
Проблема в том, что любая строка с состоянием S в общем доступе, при изменении строки в одном из процессоров нужно на всякий случай уведомлять остальные, при этом даже если этой строки нет в других процессорах. 

Для этого ввели новое состояние E (exclusive). Когда строка загружается в кэш, если два возможных состояния, которые она получит. Если копия строки есть в других кэшах, то она получит состояние S и модель работы при изменениях останется такой же. Если копий нет, то получит состояние E, означающее что копия данной строки является единственной. При внесении изменений не нужно никого уведомлять. Если один из процессоров получает копию строки, которая находится в другом процессоре в состоянии E, то в обоих процессорах ее статус меняется на S. 

Недостаток в том что когда в кэше копия строки в модифицированном виде (следовательно, в оперативной памяти старая копия) и второй процессор отправляет запрос на чтение этой строки, первому процессору придется обновлять данные в оперативной памяти, чтобы второй получил актуальную строку. Для решения этой проблемы процессоры могут обмениваться строками напрямую.

### MOESI
Ввели состояние O (owned). Когда все копии в состоянии S, запросы на чтение отправляются оперативной памяти. Когда в одном из процессоров строка в состоянии M, при запросе на чтение M в первом процессоре меняется на O и пересылается второму процессору, в котором строке присвоят статус S. Пока она в состоянии O, она продолжит отвечать на запрос чтения всем остальным процессорам. Когда первому процессору будет необходимо ее модифицировать, все разделяемые копии получат статус I. Затем у актуальной строки буде статус E, после изменений M.

В случае если в первом процессоре у строки состояние O, а во втором S, и изменение происходит во втором процессоре, то тогда данные из первого процессора будут выгружены в оперативную память, строка в первом процессоре поменяет свой статус на I, а строка во втором процессоре состояние M.

Проблема в том, что при чтении данных с разделяемыми строками приходится постоянно обращаться к оперативной памяти вместо их прямого получения из другого кэша. Эта проблема решена в протоколе MESIF, в котором вместо O добавили состояние F (forwarded). Процессор, в кэше которого есть строка, будет отвечать на запросы других процессоров. Чтобы избегать замещения строки с состоянием F, старой копии присваивается состояние S, а новой копии состояние F. Если эта строка будет заменена другой строкой, то запрос на получение строки будет перенаправлен оперативной памяти. Появлется проблема необходимости выгрузки измененных данных, когда получаем строку, чья копия есть в другом кэше в модифицированном состоянии.